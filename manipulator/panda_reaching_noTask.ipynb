{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) 2008 Idiap Research Institute, http://www.idiap.ch/\n",
    "    \n",
    "Written by Suhan Shetty <suhan.shetty@idiap.ch>,\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Motion Planning without task-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: torch_batch_svd (https://github.com/KinglittleQ/torch-batch-svd) is not installed and is required for maximum efficiency of special_procrustes. Using torch.svd as a fallback.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "torch.set_default_dtype(torch.float64)\n",
    "\n",
    "import numpy as np\n",
    "np.set_printoptions(2, suppress=True)\n",
    "torch.set_printoptions(2, sci_mode=False)\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from panda_kinematics import PandaKinematics\n",
    "from ttgo import TTGO\n",
    "from manipulator_utils import exp_space, test_robotics_task\n",
    "from utils import Point2PointMotion, test_ttgo\n",
    "from panda_cost_utils import PandaCost,SDF_Cost \n",
    "device = \"cpu\" #torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")from motion_generation_utils import Point2PointMotion,Point2PointMotionCostFcn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the environment (SDF and for graphics visualization in pybullet)\n",
    "import sys\n",
    "DATA_PATH = './data'\n",
    "body_sphere_path = './data/sphere_setting.npy'\n",
    "sdf_path = './data/sdf.npy'\n",
    "urdf_path = './data/urdf/frankaemika_new/panda_arm.urdf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pick_from = \"shelf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the model and the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w:  0 1 1 0 1\n",
      "b:  1 0.05 0.05 1 1\n"
     ]
    }
   ],
   "source": [
    "# Load the parameters from the training\n",
    "w_goal,w_obst,w_orient, w_ee, w_control = (0,1,1,0,1)\n",
    "b_goal,b_obst,b_orient, b_ee, b_control = (1,0.05,0.05,1,1)\n",
    "\n",
    "print(\"w: \",w_goal,w_obst,w_orient, w_ee, w_control)\n",
    "print(\"b: \",b_goal,b_obst,b_orient, b_ee, b_control)\n",
    "\n",
    "d0_w = 50\n",
    "K = 2\n",
    "margin= 0.1\n",
    "dt = 0.05 #model['dt'] #\n",
    "basis = 'rbf'\n",
    "d_type = 'uniform'\n",
    "\n",
    "Rd_0 = torch.tensor([[ 0.7071,0.7071,0.], [0.,0.,1],[0.7071, -0.7071, 0.]]).to(device) # desired orientation\n",
    "v_d = torch.tensor([0.,0.,1.]).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sdf = np.load('./data/sdf.npy', allow_pickle=True)[()]\n",
    "sdf_matr = data_sdf['sdf_matr']  # SDF tensor\n",
    "bounds = torch.tensor(data_sdf['bounds']).to(device) # Bound of the environment\n",
    "env_bound = data_sdf['env_bound']  \n",
    "shelf_bound = data_sdf['shelf_bound'] \n",
    "box_bound = data_sdf['box_bound'] \n",
    "\n",
    "sdf_tensor = torch.from_numpy(sdf_matr).to(device)\n",
    "sdf_cost = SDF_Cost(sdf_tensor=sdf_tensor, domain=bounds, device=device)\n",
    "\n",
    "data_keys = np.load('./data/sphere_setting.npy', allow_pickle=True)[()]# key_points\n",
    "status_array = data_keys['status_array']\n",
    "body_radius = data_keys['body_radius']\n",
    "relative_pos = data_keys['relative_pos']\n",
    "\n",
    "key_points_weight = torch.from_numpy(status_array).to(device)>0 # 8xMx1\n",
    "key_points_weight[-1] = True # activates thesphere on the gripper (inactie by default)\n",
    "key_points_margin = torch.from_numpy(body_radius).to(device) #\n",
    "key_points_pos = torch.from_numpy(relative_pos).to(device)\n",
    "\n",
    "key_points_margin[-1] = margin  # end-effector-upper part\n",
    "key_points_margin[-1][-1]= margin # gripper\n",
    "\n",
    "key_points = [key_points_pos, key_points_weight, key_points_margin]\n",
    "panda = PandaKinematics(device=device, key_points_data=key_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##############################################################################\n",
    "# Define the domain  and cost function\n",
    "\n",
    "# domain of joint angles\n",
    "n_joints=7\n",
    "\n",
    "# Discretize weights\n",
    "max_w= 1*panda.theta_max\n",
    "min_w = 1*panda.theta_min\n",
    "\n",
    "d_w_all =  [d0_w]*n_joints# np.linspace(50,100,n_joints)\n",
    "d_w = [int(d_w_all[joint]) for joint in range(n_joints)]\n",
    "domain = [torch.linspace(min_w[i],max_w[i],d_w[i]) for i in range(n_joints)]*K\n",
    "\n",
    "\n",
    "# Desired orientation of ee at the via-point\n",
    "theta_limits = [panda.theta_min, panda.theta_max]\n",
    "p2p = Point2PointMotion(dt=dt, K=K, n=n_joints, basis=basis,\n",
    "                            bounds=theta_limits, device=device)\n",
    "pandaCost = PandaCost(p2p_motion=p2p,robot=panda, sdf_cost=sdf_cost,Rd_0=Rd_0, v_d=v_d,\n",
    "                    b_obst=b_obst,b_goal=b_goal, b_ee =b_ee,\n",
    "                    b_control=b_control, b_orient=b_orient, \n",
    "                    device=device)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the via-point problem only (intial and final configurations)\n",
    "# theta_0 = torch.tensor([ -0.5,  -1.,  0.5, -2.,  0.4,  2.,  1.]).reshape(1,-1).to(device) # nominal pose for picking from shelf\n",
    "# theta_0 = torch.tensor([ 0.17, -0.99,  0.99, -1.86,  0.83,  1.15, -1.49]).reshape(1,-1).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cost functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_all(x):\n",
    "    return pandaCost.cost_j2j(x, theta_0, theta_1)\n",
    "\n",
    "\n",
    "\n",
    "def cost(x):\n",
    "    return cost_all(x)[:,0]\n",
    "\n",
    "def pdf(x):\n",
    "    return torch.exp(-cost(x)**2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TT-Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pybullet_data\n",
    "from panda_visualization_utils import *\n",
    "import pybullet as p\n",
    "from functools import partial\n",
    "\n",
    "p.connect(p.GUI)\n",
    "data = np.load(sdf_path, allow_pickle=True)[()]\n",
    "sdf_matr = data['sdf_matr']  #SDF tensor\n",
    "obstacles = data['obstacles'] #obstacles parameters\n",
    "colors = [[0.8, 0.5, 0.5, 1]]*len(obstacles)\n",
    "obj_id, init_id, target_id, border_id, obstacle_ids = init_pybullet (np.zeros(3), np.zeros(3), obstacles, colors=colors)\n",
    "p.setPhysicsEngineParameter(enableFileCaching=0)\n",
    "p.setAdditionalSearchPath(pybullet_data.getDataPath())\n",
    "p.configureDebugVisualizer(p.COV_ENABLE_GUI,0)\n",
    "robot_urdf ='./data/urdf/frankaemika_new/panda_arm.urdf'\n",
    "robot_id = p.loadURDF(fileName=robot_urdf)\n",
    "dof = p.getNumJoints(robot_id)\n",
    "pb_joint_indices = np.arange(7)\n",
    "joint_limits = get_joint_limits(robot_id,pb_joint_indices)\n",
    "mean_pose = 0.5*(joint_limits[0]+joint_limits[1])\n",
    "set_q_std = partial(set_q,robot_id, pb_joint_indices)\n",
    "rmodel = pin.buildModelFromUrdf(robot_urdf)\n",
    "rdata = rmodel.createData()\n",
    "pin_frame_names = [f.name for f in rmodel.frames]\n",
    "ee_frame_id = rmodel.getFrameId('panda_hand_joint')\n",
    "alpha = np.deg2rad(52)\n",
    "quat = p.getQuaternionFromAxisAngle((0,0,1),alpha)\n",
    "p.resetBasePositionAndOrientation(robot_id, (0,0,0.05), quat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-35f011895f9d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mik_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.data/panda_ik_solutions.pickle'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# load init and final configurations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest_theta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mik_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'theta'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtest_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mik_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'task'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "ik_data = torch.load('.data/panda_ik_solutions.pickle') # load init and final configurations\n",
    "test_theta = ik_data['theta']\n",
    "test_x = ik_data['task']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross device is cpu\n",
      "Cross-approximation over a 14D domain containing 6.10352e+23 grid points:\n",
      "Note: The algorithm converges as the ratio tt-new-norm/tt-old-norm settles to 1. For TTGO, the convergence is not important, just keep iterating as long as the ratio > 1\n",
      "iter: 0 | tt-new-norm/tt-old-norm: 5.359e-08 | time:   0.4530 | largest rank:   1\n",
      "iter: 1 | tt-new-norm/tt-old-norm: 1.075e+05 | time:   3.2866 | largest rank:   3\n",
      "iter: 2 | tt-new-norm/tt-old-norm: 1.787e+00 | time:   6.2392 | largest rank:   3\n",
      "iter: 3 | tt-new-norm/tt-old-norm: 4.067e-01 | time:   9.0105 | largest rank:   3\n",
      "iter: 4 | tt-new-norm/tt-old-norm: 1.201e+00 | time:  11.8648 | largest rank:   3 <- max_iter was reached: 5\n",
      "Did 46350 function evaluations, which took 11.19s (4142 evals/s)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fit the TT-model\n",
    "# with torch.no_grad():\n",
    "s1 = np.random.randint(0,test_theta.shape[0]-1)\n",
    "s2 = np.random.randint(0,test_theta.shape[0]-1)\n",
    "\n",
    "\n",
    "theta_0 = test_theta[s1].reshape(1,-1).to(device)\n",
    "theta_1 = test_theta[s2].reshape(1,-1).to(device)\n",
    "\n",
    "tt_model = tt_utils.cross_approximate(fcn=pdf,  domain=[x.to(device) for x in domain], \n",
    "                        rmax=200, nswp=20, eps=1e-3, verbose=True, \n",
    "# Refine the discretization and interpolate the model\n",
    "scale_factor = 10\n",
    "site_list = torch.arange(len(domain))#len(domain_task)+torch.arange(len(domain_decision))\n",
    "domain_new = tt_utils.refine_domain(domain=domain, \n",
    "                                    site_list=site_list,\n",
    "                                    scale_factor=scale_factor, device=device)\n",
    "tt_model_new = tt_utils.refine_model(tt_model=tt_model.to(device), \n",
    "                                    site_list=site_list,\n",
    "                                    scale_factor=scale_factor, device=device)                        kickrank=5, device=device)\n",
    "\n",
    "\n",
    "ttgo = TTGO(tt_model=tt_model_new, domain=domain_new, cost=cost,device=device)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a random task find the decision variables (multiple solutions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost-mean-tt: tensor([0.25, 0.02, 0.01, 0.27])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "n_solutions= 10\n",
    "n_samples_tt = 100\n",
    "n_samples_rand= 1000\n",
    "alpha=0.75; norm=1 ;\n",
    "\n",
    "t1 = time.time()\n",
    "samples_tt, samples_idx = ttgo.sample_tt(n_samples=n_samples_tt, alpha=alpha)\n",
    "state_k_tt = ttgo.choose_top_k_sample(samples_tt,n_solutions)[0]\n",
    "t2=time.time()\n",
    "\n",
    "#Optimize\n",
    "state_k_tt_opt = 1*state_k_tt\n",
    "for i, state in enumerate(state_k_tt):\n",
    "    state_k_tt_opt[i,:],results= ttgo.optimize(state,bound=True)\n",
    "t3 = time.time()\n",
    "             \n",
    "c_tt =  cost_all(state_k_tt_opt)\n",
    "\n",
    "print(\"Cost-mean-tt:\",torch.mean(c_tt,dim=0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the decision variables construct the joint angle trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Costs:  tensor([0.21, 0.32, 0.21, 0.26, 0.26, 0.31, 0.28, 0.23, 0.23, 0.24])\n"
     ]
    }
   ],
   "source": [
    "n_joints=7\n",
    "theta_bounds = [panda.min_config, panda.max_config]\n",
    "p2p_ =Point2PointMotion(dt=0.001, K=K, n=n_joints,bounds=theta_bounds, basis=basis, device=device)\n",
    "\n",
    "x = 1*state_k_tt_opt\n",
    "w = x[:] # basis weights\n",
    "theta_t = p2p_.gen_traj_p2p(theta_0.repeat(n_solutions,1),theta_1.repeat(n_solutions,1),w) # batch x time x joint \n",
    "\n",
    "\n",
    "print(\"Costs: \", cost(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Joint Violate: \", torch.sum(theta_t < panda.theta_min_robot) + torch.sum(theta_t > panda.theta_max_robot) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the joint angle trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-922e33cb153c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mset_q_std\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta_t\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "time.sleep(3)\n",
    "dt = 0.01\n",
    "for k_ in range(n_solutions):\n",
    "    set_q_std(theta_t[0,0,:])\n",
    "    T = theta_t.shape[1]\n",
    "    time.sleep(30*dt)\n",
    "    for t in range(T):\n",
    "        set_q_std(theta_t[k_,t,:])\n",
    "        time.sleep(1*dt)\n",
    "    time.sleep(10*dt)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
