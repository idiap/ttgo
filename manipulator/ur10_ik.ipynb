{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: torch_batch_svd (https://github.com/KinglittleQ/torch-batch-svd) is not installed and is required for maximum efficiency of special_procrustes. Using torch.svd as a fallback.\n",
      "device:  cpu\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "import numpy as np\n",
    "np.set_printoptions(4, suppress=True)\n",
    "torch.set_printoptions(4, sci_mode=False)\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from ttgo import TTGO\n",
    "import tt_utils\n",
    "from utils import test_ttgo\n",
    "from ur10_kinematics import Ur10Kinematics\n",
    "from manipulator_utils import dist_orientation_fixed\n",
    "device = 'cpu'#torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device: \", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_trained_model = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_trained_model:\n",
    "    trained_model = torch.load('ur10_ik.pickle')\n",
    "    b_goal,b_orient = trained_model['b']\n",
    "    d0_theta = trained_model['d0_theta']\n",
    "    dh_x = trained_model['dh_x']\n",
    "    domain = trained_model['domain']\n",
    "    Rd_0 = trained_model['Rd_0']\n",
    "    test_task = trained_model['test_task']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the robot and the environment\n",
    "\n",
    "ur10 = Ur10Kinematics(device=device)\n",
    "n_joints= ur10.n_joints\n",
    "# Desired orientation (fixed orientation)\n",
    "Rd_0 = torch.eye(3).to(device)\n",
    "# Rd_0[1:,1:]*=-1\n",
    "def cost_all(x): # For inverse kinematics\n",
    "    x = x.to(device)\n",
    "    batch_size = x.shape[0]\n",
    "    goal_loc = x[:,:3]\n",
    "    q = x[:,3:]  # batch x joint angles\n",
    "    _, end_loc, end_R = ur10.forward_kin(q) # batch x joint x keys x positions\n",
    "    # cost on error in end-effector position\n",
    "    d_goal = torch.linalg.norm(end_loc-goal_loc, dim=1)\n",
    "    # cost on error in end-effector orientation\n",
    "    d_orient = dist_orientation_fixed(Rd_0,end_R,device=device)\n",
    "    c_total = 0.5*(d_goal/b_goal + d_orient/b_orient)\n",
    "    c_return = torch.cat((c_total.view(-1,1), d_goal.view(-1,1), d_orient.view(-1,1)),dim=-1)\n",
    "    return c_return\n",
    "\n",
    "def cost(x):\n",
    "    return cost_all(x)[:,0]\n",
    "\n",
    "\n",
    "def pdf(x):\n",
    "    x = x.to(device)\n",
    "    pdf_ = torch.exp(-cost(x)**2) \n",
    "    return pdf_\n",
    "\n",
    "#####################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 0., 1.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Rd_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discretization:  [249, 251, 132, 60, 60, 60, 60, 60, 60]\n",
      "cross device is cpu\n",
      "Cross-approximation over a 9D domain containing 3.84906e+17 grid points:\n",
      "Note: The algorithm converges as the ratio tt-new-norm/tt-old-norm settles to 1. For TTGO, the convergence is not important, just keep iterating as long as the ratio > 1\n",
      "iter: 0  | tt-new-norm/tt-old-norm: 0.000e+00 | time:   0.0554 | largest rank:   1\n",
      "iter: 1  | tt-new-norm/tt-old-norm: 1.975e+13 | time:   0.1947 | largest rank:   4\n",
      "iter: 2  | tt-new-norm/tt-old-norm: 1.211e+00 | time:   0.4516 | largest rank:   7\n",
      "iter: 3  | tt-new-norm/tt-old-norm: 1.375e+00 | time:   0.9230 | largest rank:  10\n",
      "iter: 4  | tt-new-norm/tt-old-norm: 1.222e+00 | time:   1.5941 | largest rank:  13\n",
      "iter: 5  | tt-new-norm/tt-old-norm: 1.114e+00 | time:   2.5614 | largest rank:  16\n",
      "iter: 6  | tt-new-norm/tt-old-norm: 1.010e+00 | time:   3.9184 | largest rank:  19\n",
      "iter: 7  | tt-new-norm/tt-old-norm: 1.015e+00 | time:   5.7780 | largest rank:  22\n",
      "iter: 8  | tt-new-norm/tt-old-norm: 9.715e-01 | time:   8.1582 | largest rank:  25\n",
      "iter: 9  | tt-new-norm/tt-old-norm: 8.734e-01 | time:  11.1627 | largest rank:  28\n",
      "iter: 10 | tt-new-norm/tt-old-norm: 1.057e+00 | time:  15.1281 | largest rank:  31\n",
      "iter: 11 | tt-new-norm/tt-old-norm: 1.179e+00 | time:  20.0775 | largest rank:  34\n",
      "iter: 12 | tt-new-norm/tt-old-norm: 1.048e+00 | time:  26.0245 | largest rank:  37\n",
      "iter: 13 | tt-new-norm/tt-old-norm: 1.025e+00 | time:  32.7949 | largest rank:  40\n",
      "iter: 14 | tt-new-norm/tt-old-norm: 9.534e-01 | time:  40.1786 | largest rank:  43\n",
      "iter: 15 | tt-new-norm/tt-old-norm: 1.046e+00 | time:  49.9217 | largest rank:  46\n",
      "iter: 16 | tt-new-norm/tt-old-norm: 1.112e+00 | time:  60.2536 | largest rank:  49\n",
      "iter: 17 | tt-new-norm/tt-old-norm: 1.031e+00 | time:  71.6696 | largest rank:  52\n",
      "iter: 18 | tt-new-norm/tt-old-norm: 1.055e+00 | time:  84.2743 | largest rank:  55\n",
      "iter: 19 | tt-new-norm/tt-old-norm: 1.011e+00 | time:  99.1964 | largest rank:  58 <- max_iter was reached: 20\n",
      "Did 32279960 function evaluations, which took 90.04s (3.585e+05 evals/s)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if not use_trained_model:\n",
    "    # Define the domain\n",
    "    d0_theta = 60;\n",
    "    dh_x = 0.01\n",
    "    d_type = 'uniform'\n",
    "    b_goal = 0.05; b_orient = 0.2;\n",
    "\n",
    "    d_theta_all = [d0_theta]*n_joints\n",
    "    d_theta = [int(d_theta_all[joint]) for joint in range(n_joints)]\n",
    "    if d_type == 'uniform':\n",
    "        domain_decision = [torch.linspace(0.5*ur10.theta_min[i],0.5*ur10.theta_max[i],d_theta[i]).to(device) for i in range(n_joints)]\n",
    "    else: # logarithmic scaling\n",
    "        domain_decision = [exp_space(0.5*ur10.theta_min[i].to('cpu'),0.5*ur10.theta_max[i].to('cpu'),d_theta[i]).to(device) for i in range(n_joints)]\n",
    "\n",
    "    # Find the work-space\n",
    "    n_test = 1000\n",
    "    test_theta = torch.zeros(n_test,n_joints).to(device)\n",
    "    for i in range(n_joints):\n",
    "        unif = torch.distributions.uniform.Uniform(low = domain_decision[i][0],high=domain_decision[i][-1])\n",
    "        test_theta[:,i]= torch.tensor([unif.sample() for i in range(n_test)]).to(device)\n",
    "    _, test_xpos, _ = ur10.forward_kin(test_theta)\n",
    "    x_min,_ = torch.min(test_xpos, dim=0)\n",
    "    x_max,_ = torch.max(test_xpos,dim=0)\n",
    "    x_min[-1] = 0.1\n",
    "    idx_select = test_xpos[:,-1]>x_min[-1]\n",
    "    test_task = test_xpos[idx_select,:]\n",
    "\n",
    "    # discretize the domain\n",
    "    domain_task = [torch.linspace(x_min[i], x_max[i], int((x_max[i]-x_min[i])/dh_x)).to(device) for i in range(3)]\n",
    "    domain = domain_task + domain_decision\n",
    "    print(\"Discretization: \",[len(x) for x in domain])\n",
    "    tt_model = tt_utils.cross_approximate(fcn=pdf,  domain=[x.to(device) for x in domain], \n",
    "                            rmax=200, nswp=20, eps=1e-3, verbose=True, \n",
    "    # Refine the discretization and interpolate the model\n",
    "    scale_factor = 10\n",
    "    site_list = torch.arange(len(domain))#len(domain_task)+torch.arange(len(domain_decision))\n",
    "    domain_new = tt_utils.refine_domain(domain=domain, \n",
    "                                        site_list=site_list,\n",
    "                                        scale_factor=scale_factor, device=device)\n",
    "    tt_model_new = tt_utils.refine_model(tt_model=tt_model.to(device), \n",
    "                                        site_list=site_list,\n",
    "                                        scale_factor=scale_factor, device=device)                        kickrank=5, device=device)\n",
    "    \n",
    "    \n",
    "    ttgo = TTGO(tt_model=tt_model_new, domain=domain_new, cost=cost,device=device)\n",
    "\n",
    "    \n",
    "    \n",
    "    # Save\n",
    "    file_name = 'ur10_ik.pickle'\n",
    "    torch.save({\n",
    "    'tt_model':ttgo.tt_model,\n",
    "    'b': (b_goal,b_orient),\n",
    "    'd0_theta':d0_theta,\n",
    "    'dh_x': dh_x,\n",
    "    'domain': domain_new,\n",
    "    'Rd_0':Rd_0,\n",
    "    'test_task':test_task\n",
    "    }, file_name)\n",
    "\n",
    "\n",
    "else:\n",
    "    tt_model = trained_model['tt_model'].to(device)\n",
    "    ttgo = TTGO(tt_model = tt_model.to(device), domain=domain,cost=cost)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-7-a5d5b61aa8a6>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-7-a5d5b61aa8a6>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    .\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pybullet_data\n",
    "from panda_visualization_utils import *\n",
    "import pybullet as p\n",
    "from functools import partial\n",
    "# import the environment (SDF and for graphics visualization in pybullet)\n",
    "import sys\n",
    "\n",
    "import sys\n",
    "DATA_PATH = './data'\n",
    "robot_urdf = DATA_PATH + '/urdf/ur10/ur10.urdf'\n",
    "\n",
    "\n",
    "physics_client_id = p.connect(p.GUI)\n",
    "p.setPhysicsEngineParameter(enableFileCaching=0)\n",
    "p.setAdditionalSearchPath(pybullet_data.getDataPath())\n",
    "p.configureDebugVisualizer(p.COV_ENABLE_GUI,0)\n",
    "\n",
    "p.resetSimulation()\n",
    "\n",
    "# for i in range(8):\n",
    "#     print(i, p.getJointInfo(robot_id, i)[1])\n",
    "    \n",
    "robot_id = p.loadURDF(robot_urdf)\n",
    "\n",
    "dof = p.getNumJoints(robot_id)\n",
    "pb_joint_indices = np.arange(1,7)\n",
    "joint_limits = get_joint_limits(robot_id,pb_joint_indices)\n",
    "set_q_std = partial(set_q,robot_id, pb_joint_indices)\n",
    "\n",
    "plane_id = p.loadURDF('plane.urdf')\n",
    "p.resetBasePositionAndOrientation(plane_id, (0,0,0.), (0,0,0,1))\n",
    "\n",
    "#for visualizing the desired target\n",
    "_,_,ball_id = create_primitives(radius=0.05)\n",
    "\n",
    "ee_pb_id = 7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Prepare for the task\n",
    "# sites_task = list(range(3))\n",
    "# ttgo.set_sites(sites_task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.27, -0.22,  0.86])\n",
      "Cost-mean-tt: tensor([0.00, 0.00, 0.00])\n"
     ]
    }
   ],
   "source": [
    "s = np.random.randint(0,test_task.shape[0]-1)\n",
    "sample_xe = test_task[s] #\n",
    "print(sample_xe)\n",
    "\n",
    "\n",
    "n_solutions= 10\n",
    "n_samples_tt = 100*n_solutions\n",
    "n_samples_rand= 1*n_samples_tt\n",
    "\n",
    "alpha=0.9; \n",
    "\n",
    "t1 = time.time()\n",
    "samples_tt, samples_idx = ttgo.sample_tt(n_samples=n_samples_tt, x_task=sample_xe.reshape(1,-1),alpha=alpha)\n",
    "state_k_tt = ttgo.choose_top_k_sample(samples_tt,n_solutions)[0]\n",
    "\n",
    "#Optimize\n",
    "state_k_tt_opt = 1*state_k_tt\n",
    "for i, state in enumerate(state_k_tt):\n",
    "    state_k_tt_opt[i,:],results= ttgo.optimize(state,bound=True)\n",
    "t2 = time.time()\n",
    "             \n",
    "c_tt =  cost_all(state_k_tt_opt)\n",
    "print(\"Cost-mean-tt:\",torch.mean(c_tt,dim=0))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_target = sample_xe[:3].cpu().numpy()\n",
    "joint_angles_k = state_k_tt[:,3:].cpu().numpy() \n",
    "joint_angles_k_opt = state_k_tt_opt[:,3:].cpu().numpy() \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-ca05d16951d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mset_q_std\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjoint_angles_k\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mset_q_std\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjoint_angles_k_opt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# _,_,test_sphere = create_primitives(p.GEOM_SPHERE, radius = 0.02)\n",
    "# p.resetBasePositionAndOrientation(test_sphere, (0,0,1.), (0,0,0,1))\n",
    "_ , _,sphere_id = create_primitives(p.GEOM_SPHERE, radius = 0.02)\n",
    "pos = x_target[:]\n",
    "\n",
    "p.resetBasePositionAndOrientation(sphere_id, pos, (0,0,0,1))\n",
    "\n",
    "\n",
    "k = joint_angles_k.shape[0]\n",
    "dt = 1\n",
    "dT = 2\n",
    "for i in range(2*k):\n",
    "    set_q_std(joint_angles_k[i%k])\n",
    "    time.sleep(dt)\n",
    "    set_q_std(joint_angles_k_opt[i%k])\n",
    "    time.sleep(2*dt)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
