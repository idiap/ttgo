{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) 2008 Idiap Research Institute, http://www.idiap.ch/\n",
    "    \n",
    "Written by Suhan Shetty <suhan.shetty@idiap.ch>,\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/idiap/temp/sshetty/miniconda/envs/pyml/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: torch_batch_svd (https://github.com/KinglittleQ/torch-batch-svd) is not installed and is required for maximum efficiency of special_procrustes. Using torch.svd as a fallback.\n",
      "device:  cuda\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from panda_kinematics import PandaKinematics\n",
    "\n",
    "import torch\n",
    "torch.set_default_dtype(torch.float64)\n",
    "\n",
    "import numpy as np\n",
    "np.set_printoptions(2, suppress=True)\n",
    "torch.set_printoptions(2, sci_mode=False)\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from panda_cost_utils import SDF_Cost, PandaCost\n",
    "from ttgo import TTGO\n",
    "import tt_utils\n",
    "from utils import test_ttgo\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device: \", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-params\n",
    "d0_theta = 50\n",
    "dh_x = 0.05\n",
    "margin = 0\n",
    "kr = 5\n",
    "b_goal = 0.05 ; b_obst= 0.01; b_orient=0.2;\n",
    "nswp=20; rmax=500; kr=2;\n",
    "d_type = \"uniform\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the cost/pdf function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sdf = np.load('./data/sdf.npy', allow_pickle=True)[()]\n",
    "sdf_matr = data_sdf['sdf_matr']  \n",
    "bounds = torch.tensor(data_sdf['bounds']).to(device) # Bound of the environment\n",
    "sdf_tensor = torch.from_numpy(sdf_matr).to(device)\n",
    "sdf_cost = SDF_Cost(sdf_tensor=sdf_tensor, domain=bounds, device=device)\n",
    "env_bound = data_sdf['env_bound']  \n",
    "shelf_bound = data_sdf['shelf_bound'] \n",
    "box_bound = data_sdf['box_bound'] \n",
    "\n",
    "# key-points on the body of the robot for collision check\n",
    "data_keys = np.load('./data/sphere_setting.npy', allow_pickle=True)[()]# key_points\n",
    "status_array = data_keys['status_array']\n",
    "body_radius = data_keys['body_radius']\n",
    "relative_pos = data_keys['relative_pos']\n",
    "key_points_weight = torch.from_numpy(status_array).float().to(device) >0 # 8xMx1\n",
    "key_points_weight[-1] = 1*margin\n",
    "key_points_margin = torch.from_numpy(body_radius).float().to(device)#\n",
    "key_points_pos = torch.from_numpy(relative_pos).float().to(device)\n",
    "key_points = [key_points_pos, key_points_weight, key_points_margin]\n",
    "\n",
    "# define the robot\n",
    "panda = PandaKinematics(device=device, key_points_data=key_points)\n",
    "\n",
    "############################################################\n",
    "\n",
    "# Define the cost function\n",
    "\n",
    "# Specify the doesired orientation\n",
    "Rd_0 = torch.tensor([[ 0.7071,0.7071,0.], [0.,0.,1],[0.7071, -0.7071, 0.]]).to(device) # desired orientation\n",
    "v_d = torch.tensor([0.,0.,1.]).to(device)\n",
    "# Rd = torch.tensor([[ 0,0.,0.], [0.,0.,1],[0., 0., 0.]])\n",
    "\n",
    "pandaCost = PandaCost(robot=panda, sdf_cost=sdf_cost,\n",
    "                    Rd_0=Rd_0, v_d=v_d,b_obst=b_obst, \n",
    "                    b_goal=b_goal,b_orient=b_orient,device=device)  \n",
    "\n",
    "\n",
    "def cost(x): # For inverse kinematics\n",
    "    return pandaCost.cost_ik(x)[:,0]\n",
    "\n",
    "def cost_all(x): # For inverse kinematics\n",
    "    return pandaCost.cost_ik(x)\n",
    "\n",
    "def pdf(x):\n",
    "    x = x.to(device)\n",
    "    pdf_ = torch.exp(-cost(x)**2) \n",
    "    return pdf_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discretization:  [5, 15, 15, 50, 50, 50, 50, 50, 50, 50]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "############################################################################\n",
    "# Define the domain for discretization\n",
    "\n",
    "n_joints=7\n",
    "d_theta_all = [d0_theta]*n_joints\n",
    "d_theta = [int(d_theta_all[joint]) for joint in range(n_joints)]\n",
    "\n",
    "# type of discretization of intervals of decision variables\n",
    "if d_type == 'uniform':\n",
    "    domain_decision = [torch.linspace(panda.theta_min[i],panda.theta_max[i],d_theta[i]).to(device) for i in range(n_joints)]\n",
    "else: # logarithmic scaling\n",
    "    domain_decision = [exp_space(panda.theta_min[i],panda.theta_max[i],d_theta[i]).to(device) for i in range(n_joints)]\n",
    "\n",
    "# task space of the manipulator (the shelf)\n",
    "env_bounds = torch.from_numpy(shelf_bound)\n",
    "x_min = env_bounds[:,0]\n",
    "x_max = env_bounds[:,1]\n",
    "x_max[0] = 0.75; x_min[0]=0.45\n",
    "x_max[1] = x_max[1]-0.1\n",
    "x_min[1] = x_min[1]+0.1\n",
    "x_max[-1] = 0.75; x_min[-1] = 0.\n",
    "\n",
    "\n",
    "domain_task = [torch.linspace(x_min[i], x_max[i], int((x_max[i]-x_min[i])/dh_x)) for i in range(3)]\n",
    "d_task = [len(domain_task[i]) for i in range(3)]\n",
    "\n",
    "\n",
    "domain_task = [x.to(device) for x in domain_task]\n",
    "domain_decision = [x.to(device) for x in domain_decision]\n",
    "\n",
    "domain = domain_task + domain_decision\n",
    "print(\"Discretization: \",[len(x) for x in domain])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Find tt_model of pdf_goal:\n",
      "cross device is cuda\n",
      "Cross-approximation over a 10D domain containing 8.78906e+14 grid points:\n",
      "iter: 0  | tt-error: 1.026e+00, test-error:6.214e-01 | time:   0.3533 | largest rank:   1\n",
      "iter: 1  | tt-error: 9.504e-01, test-error:2.051e-01 | time:   0.4996 | largest rank:   6\n",
      "iter: 2  | tt-error: 1.960e-01, test-error:7.161e-02 | time:   0.6656 | largest rank:  11\n",
      "iter: 3  | tt-error: 6.617e-02, test-error:2.760e-02 | time:   0.8586 | largest rank:  16\n",
      "iter: 4  | tt-error: 2.537e-02, test-error:1.434e-02 | time:   1.1003 | largest rank:  21\n",
      "iter: 5  | tt-error: 1.186e-02, test-error:8.944e-03 | time:   1.3743 | largest rank:  26\n",
      "iter: 6  | tt-error: 8.796e-03, test-error:3.374e-03 | time:   1.7018 | largest rank:  31\n",
      "iter: 7  | tt-error: 3.577e-03, test-error:2.026e-03 | time:   2.1034 | largest rank:  36\n",
      "iter: 8  | tt-error: 2.094e-03, test-error:9.797e-04 | time:   2.5815 | largest rank:  41\n",
      "iter: 9  | tt-error: 1.049e-03, test-error:7.697e-04 | time:   3.1415 | largest rank:  46\n",
      "iter: 10 | tt-error: 7.671e-04, test-error:3.519e-04 | time:   3.7688 | largest rank:  51 <- converged: eps < 0.001\n",
      "Did 6469620 function evaluations, which took 1.022s (6.333e+06 evals/s)\n",
      "\n",
      "tensor([ 1,  3,  8, 18, 33, 31, 20, 14,  5,  1,  1])\n",
      "Find tt_model of pdf_orient:\n",
      "cross device is cuda\n",
      "Cross-approximation over a 7D domain containing 7.8125e+11 grid points:\n",
      "iter: 0  | tt-error: 1.214e+00, test-error:2.981e-01 | time:   0.0605 | largest rank:   1\n",
      "iter: 1  | tt-error: 4.548e-01, test-error:1.254e-01 | time:   0.1492 | largest rank:   6\n",
      "iter: 2  | tt-error: 9.530e-02, test-error:8.227e-02 | time:   0.2447 | largest rank:  11\n",
      "iter: 3  | tt-error: 8.416e-02, test-error:7.414e-02 | time:   0.3613 | largest rank:  16\n",
      "iter: 4  | tt-error: 7.406e-02, test-error:6.142e-02 | time:   0.5117 | largest rank:  21\n",
      "iter: 5  | tt-error: 6.772e-02, test-error:5.887e-02 | time:   0.6960 | largest rank:  26\n",
      "iter: 6  | tt-error: 6.095e-02, test-error:5.663e-02 | time:   0.9201 | largest rank:  31\n",
      "iter: 7  | tt-error: 6.199e-02, test-error:5.732e-02 | time:   1.1993 | largest rank:  36\n",
      "iter: 8  | tt-error: 6.274e-02, test-error:4.692e-02 | time:   1.5436 | largest rank:  41\n",
      "iter: 9  | tt-error: 5.342e-02, test-error:4.790e-02 | time:   1.9679 | largest rank:  46 <- max_iter was reached: 10\n",
      "Did 3827750 function evaluations, which took 1.035s (3.698e+06 evals/s)\n",
      "\n",
      "tensor([ 1, 40, 46, 46, 45, 45, 31,  1])\n",
      "Find tt_model of pdf_obst:\n",
      "cross device is cuda\n",
      "Cross-approximation over a 7D domain containing 7.8125e+11 grid points:\n",
      "iter: 0  | tt-error: 1.298e+00, test-error:6.170e-02 | time:   0.0686 | largest rank:   1\n",
      "iter: 1  | tt-error: 1.245e-01, test-error:9.548e-02 | time:   0.1488 | largest rank:   6\n",
      "iter: 2  | tt-error: 5.783e-02, test-error:5.857e-02 | time:   0.2403 | largest rank:  11\n",
      "iter: 3  | tt-error: 4.419e-02, test-error:3.227e-02 | time:   0.3496 | largest rank:  16\n",
      "iter: 4  | tt-error: 2.313e-02, test-error:2.943e-02 | time:   0.4966 | largest rank:  21\n",
      "iter: 5  | tt-error: 2.451e-02, test-error:2.409e-02 | time:   0.6801 | largest rank:  26\n",
      "iter: 6  | tt-error: 2.348e-02, test-error:2.527e-02 | time:   0.9092 | largest rank:  31\n",
      "iter: 7  | tt-error: 2.507e-02, test-error:2.354e-02 | time:   1.1944 | largest rank:  36\n",
      "iter: 8  | tt-error: 2.388e-02, test-error:2.319e-02 | time:   1.5471 | largest rank:  41\n",
      "iter: 9  | tt-error: 2.353e-02, test-error:2.401e-02 | time:   1.9682 | largest rank:  46 <- max_iter was reached: 10\n",
      "Did 3827750 function evaluations, which took 0.6428s (5.955e+06 evals/s)\n",
      "\n",
      "tensor([ 1, 46, 46, 46, 44, 28,  1,  1])\n",
      "Take product to compute pdf(x_task,x_decision) \n",
      "Rank of TT-model:  tensor([  1,   3,   8,  17, 263, 614, 540, 251,  89,  28,   1])\n"
     ]
    }
   ],
   "source": [
    "use_fusion = True # more efficient if True\n",
    "# for target reaching\n",
    "\n",
    "def pdf_goal(x):\n",
    "    d_goal = pandaCost.cost_goal(x)\n",
    "    return torch.exp(-(d_goal/1)**2) \n",
    "\n",
    "def pdf_orient_q(q):\n",
    "    return torch.exp(-(pandaCost.cost_orient(q)/2)**2)\n",
    "\n",
    "def pdf_obst_q(q):\n",
    "    return torch.exp(-(pandaCost.cost_obst(q)/1)**2)\n",
    "\n",
    "if use_fusion:\n",
    "    print(\"Find tt_model of pdf_goal:\")\n",
    "    tt_goal = tt_utils.cross_approximate(fcn=pdf_goal,  domain=domain, \n",
    "                            rmax=100, nswp=20, eps=1e-3, verbose=True, \n",
    "                            kickrank=5, device=device)\n",
    "    \n",
    "    print(tt_goal.ranks_tt)\n",
    "\n",
    "    print(\"Find tt_model of pdf_orient:\")\n",
    "    tt_orient_q = tt_utils.cross_approximate(fcn=pdf_orient_q,  domain=domain_decision, \n",
    "                            rmax=100, nswp=10, eps=1e-3, verbose=True, \n",
    "                            kickrank=5, device=device)\n",
    "    print(tt_orient_q.ranks_tt)\n",
    "\n",
    "\n",
    "\n",
    "    print(\"Find tt_model of pdf_obst:\")\n",
    "    tt_obst_q = tt_utils.cross_approximate(fcn=pdf_obst_q,  domain=domain_decision, \n",
    "                            rmax=100, nswp=10, eps=1e-3, verbose=True, \n",
    "                            kickrank=5, device=device)\n",
    "    print(tt_obst_q.ranks_tt)\n",
    "\n",
    "\n",
    "    # make sure the dimensions of tt_obst matches with that of tt_model desired\n",
    "    # i.e. pdf_obst(x_task,q) = pdf_obst_q(q)\n",
    "    tt_obst = tt_utils.extend_model(tt_model=tt_obst_q,site=0,n_cores=3,d=d_task).to(device)\n",
    "    tt_orient = tt_utils.extend_model(tt_model=tt_orient_q,site=0,n_cores=3,d=d_task).to(device)\n",
    "    print(\"Take product to compute pdf(x_task,x_decision) \")\n",
    "    tt_model = tt_orient.to('cpu')*tt_obst.to('cpu')\n",
    "    tt_model.round_tt(1e-3)\n",
    "    tt_model = tt_model.to('cpu')*tt_goal.to('cpu')\n",
    "    tt_model.round_tt(1e-3)\n",
    "    \n",
    "\n",
    "else: # compute the pdf directly using the cost function (less efficient) \n",
    "    def pdf(x):\n",
    "        return torch.exp(-1*cost(x)**2)\n",
    "    tt_model = tt_utils.cross_approximate(fcn=pdf,  domain=[x.to(device) for x in domain], \n",
    "                            rmax=200, nswp=20, eps=1e-3, verbose=True, \n",
    "                            kickrank=5, device=device)\n",
    "\n",
    "print(\"Rank of TT-model: \", tt_model.ranks_tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refine the discretization and interpolate the model\n",
    "scale_factor = 10\n",
    "site_list = torch.arange(len(domain))#len(domain_task)+torch.arange(len(domain_decision))\n",
    "domain_new = tt_utils.refine_domain(domain=domain, \n",
    "                                    site_list=site_list,\n",
    "                                    scale_factor=scale_factor, device=device)\n",
    "tt_model_new = tt_utils.refine_model(tt_model=tt_model.to(device), \n",
    "                                    site_list=site_list,\n",
    "                                    scale_factor=scale_factor, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################################\n",
    "ttgo = TTGO(tt_model = tt_model.to(device), domain=domain, cost=cost, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################\n",
      "Test the model\n",
      "############################\n"
     ]
    }
   ],
   "source": [
    "############################################################ \n",
    "print(\"############################\")\n",
    "print(\"Test the model\")\n",
    "print(\"############################\")\n",
    "\n",
    "# generate test set\n",
    "ns = 100\n",
    "test_task = torch.zeros(ns,len(domain_task)).to(device)\n",
    "for i in range(len(domain_task)):\n",
    "    unif = torch.distributions.uniform.Uniform(low=domain_task[i][0],high=domain_task[i][-1])\n",
    "    test_task[:,i]= torch.tensor([unif.sample() for i in range(ns)]).to(device)\n",
    "\n",
    "file_name = 'panda_ik.pickle'\n",
    "torch.save({\n",
    "    'tt_model':ttgo.tt_model,\n",
    "    'panda': panda,\n",
    "    'pandaCost':pandaCost,\n",
    "    'sdf_cost':sdf_cost,\n",
    "    'w': (pandaCost.w_goal,pandaCost.w_obst,pandaCost.w_orient),\n",
    "    'b': (b_goal,b_obst,b_orient),\n",
    "    'margin': margin,\n",
    "    'key_points_weight':key_points_weight,\n",
    "    'key_points_margin':key_points_margin,\n",
    "    'domains': domain,  \n",
    "    'Rd_0': Rd_0,\n",
    "    'v_d':v_d,\n",
    "    'test_task': test_task,\n",
    "}, file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate test set\n",
    "test_task = torch.zeros(1000,len(domain_task)).to(device)\n",
    "for i in range(len(domain_task)):\n",
    "    unif = torch.distributions.uniform.Uniform(low=domain_task[i][0],high=domain_task[i][-1])\n",
    "    test_task[:,i]= torch.tensor([unif.sample() for i in range(1000)]).to(device)\n",
    "\n",
    "ns = 100\n",
    "test_task  = test_task[(sdf_cost.sdf(test_task)-0.09)>0][:ns] # \n",
    "\n",
    "joint_angles = torch.zeros((test_task.shape[0],7))\n",
    "x_tasks = torch.zeros((test_task.shape[0],3))\n",
    "for i in range(test_task.shape[0]):\n",
    "    x_task =test_task[i].view(1,-1)\n",
    "    samples = ttgo.sample_tt(n_samples=100,alpha=0.75,x_task=x_task)\n",
    "    best_sample = ttgo.choose_best_sample(samples)[0]\n",
    "    sol,_ = ttgo.optimize(best_sample)\n",
    "    joint_angles[i] = sol[:,3:].cpu()\n",
    "    x_tasks[i] = sol[:,:3].cpu()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save({'task':x_tasks,'theta':joint_angles},\"ik_data.pickle\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pybullet build time: Sep 20 2021 20:34:14\n"
     ]
    }
   ],
   "source": [
    "import pybullet_data\n",
    "from panda_visualization_utils import *\n",
    "import pybullet as p\n",
    "from functools import partial\n",
    "# import the environment (SDF and for graphics visualization in pybullet)\n",
    "import sys\n",
    "DATA_PATH = './data'\n",
    "body_sphere_path = './data/sphere_setting.npy'\n",
    "sdf_path = './data/sdf.npy'\n",
    "urdf_path = './data/urdf/frankaemika_new/panda_arm.urdf'\n",
    "\n",
    "p.connect(p.GUI)\n",
    "data = np.load(sdf_path, allow_pickle=True)[()]\n",
    "sdf_matr = data['sdf_matr']  #SDF tensor\n",
    "obstacles = data['obstacles'] #obstacles parameters\n",
    "colors = [[0.8, 0.5, 0.5, 1]]*len(obstacles)\n",
    "obj_id, init_id, target_id, border_id, obstacle_ids = init_pybullet (np.zeros(3), np.zeros(3), obstacles, colors=colors)\n",
    "p.setPhysicsEngineParameter(enableFileCaching=0)\n",
    "p.setAdditionalSearchPath(pybullet_data.getDataPath())\n",
    "p.configureDebugVisualizer(p.COV_ENABLE_GUI,0)\n",
    "robot_urdf ='./data/urdf/frankaemika_new/panda_arm.urdf'\n",
    "robot_id = p.loadURDF(fileName=robot_urdf)\n",
    "dof = p.getNumJoints(robot_id)\n",
    "pb_joint_indices = np.arange(7)\n",
    "joint_limits = get_joint_limits(robot_id,pb_joint_indices)\n",
    "mean_pose = 0.5*(joint_limits[0]+joint_limits[1])\n",
    "set_q_std = partial(set_q,robot_id, pb_joint_indices)\n",
    "rmodel = pin.buildModelFromUrdf(robot_urdf)\n",
    "rdata = rmodel.createData()\n",
    "pin_frame_names = [f.name for f in rmodel.frames]\n",
    "ee_frame_id = rmodel.getFrameId('panda_hand_joint')\n",
    "alpha = np.deg2rad(52)\n",
    "quat = p.getQuaternionFromAxisAngle((0,0,1),alpha)\n",
    "p.resetBasePositionAndOrientation(robot_id, (0,0,0.05), quat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = np.random.randint(0,test_task.shape[0]-1)\n",
    "sample_xe =test_task[s] # torch.tensor([0.58, 0.68, 0.78])\n",
    "print(sample_xe)\n",
    "# torch.tensor([0.4435, 0.4347, 0.2139]) # bottom center\n",
    "# torch.tensor([0.4991, 0.6301, 0.3695]) # bottom left\n",
    "# torch.tensor([0.6352, 0.4708, 0.7535]) # top left\n",
    "# torch.tensor([0.6789, 0.1950, 0.6976]) # top shelf center\n",
    "# torch.tensor([0.6635, 0.6250, 0.2031]) # bottom, in, inaccessible\n",
    "# tirch.tensor([0.4228, 0.4441, 0.8760]) # top \n",
    "# sample_xe = torch.tensor([0.8, -0.1, 0.3]) #torch.tensor([0.8, -0.3, 0.35])#torch.torch.tensor([ 0.6404, 0.2350,  0.549])#torch.tensor([ 0.7130, -0.3007, -0.1276]) #\n",
    "sample_xe[0] = 0.5\n",
    "n_solutions= 2\n",
    "n_samples_tt = 200*n_solutions\n",
    "n_samples_rand= 10*n_samples_tt\n",
    "\n",
    "alpha=0.5; norm=1 ;\n",
    "\n",
    "t1 = time.time()\n",
    "samples_tt, samples_idx = ttgo.sample_tt(n_samples=n_samples_tt, x_task=sample_xe.reshape(1,-1),alpha=alpha)\n",
    "state_k_tt = ttgo.choose_top_k_sample(samples_tt,n_solutions)[0]\n",
    "\n",
    "#Optimize\n",
    "state_k_tt_opt = 1*state_k_tt\n",
    "for i, state in enumerate(state_k_tt):\n",
    "    state_k_tt_opt[i,:],_= ttgo.optimize(state,bound=True)\n",
    "t2 = time.time()\n",
    "\n",
    "             \n",
    "c_tt =  cost(state_k_tt_opt)\n",
    "\n",
    "print(\"Cost-mean-tt:\",torch.mean(c_tt,dim=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _,_,test_sphere = create_primitives(p.GEOM_SPHERE, radius = 0.02)\n",
    "# p.resetBasePositionAndOrientation(test_sphere, (0,0,1.), (0,0,0,1))\n",
    "\n",
    "x_target = sample_xe[:3].numpy()\n",
    "joint_angles_k = state_k_tt[:,3:].numpy() \n",
    "joint_angles_k_opt = state_k_tt_opt[:,3:].numpy() \n",
    "\n",
    "\n",
    "_ , _,sphere_id = create_primitives(p.GEOM_SPHERE, radius = 0.02)\n",
    "pos = x_target[:]\n",
    "\n",
    "p.resetBasePositionAndOrientation(sphere_id, pos, (0,0,0,1))\n",
    "\n",
    "\n",
    "k = joint_angles_k.shape[0]\n",
    "dt = 1\n",
    "dT = 2\n",
    "for i in range(2*k):\n",
    "    set_q_std(joint_angles_k[i%k])\n",
    "    time.sleep(dt)\n",
    "    set_q_std(joint_angles_k_opt[i%k])\n",
    "    time.sleep(2*dt)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
